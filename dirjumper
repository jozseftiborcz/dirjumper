#!/usr/bin/python

VERSION = "v0.1"
CACHE_FILE = ".dirjumper"

import sys, os, re
global IGNORE_HIDDEN_FILES

def print_msg(msg):
    print "%m:"+msg

def print_err(msg):
    print "%e:"+msg

def print_help():
    print_msg("""
dirjumper command <optional parameters>

possible commands:
    init                    Initiates .dirjumper file in the current directory
    discover <path>*        Finds and displays .dirjumper cache files starting from the 
                            given directories or the current one if nothing is given up to the root.
    scan <path>*            Adds given directories or the current one if nothing is given to the first cache found.
                            If no cache is found, gives an error.
    complete <prefixes>+    Searches accessible caches from the current directory (see discover) and display
                            possible dirnames matching prefixes
    propose <prefixes>+     Searches accessible caches from the current directory (see discover) and returns
                            possible paths matching prefixes

Prefix match algorithm:
* ? is a special prefix which means: return the shortest matching path
* if prefix ends with double colon than prefix should match a part of path, otherwise prefix should match to the 
  beginning of a dirname of the path
* if more prefix is given, consecutive prefixes should match the path starting from the last match's subdirectory.
""")

def find_cache(basedir, home_search=False):
    basedir = os.path.realpath(basedir)

    cache_path = os.path.join(basedir, CACHE_FILE)
    if os.path.exists(cache_path) and os.path.isfile(cache_path):
        return cache_path
    elif basedir != '/':
        return find_cache(os.path.dirname(basedir), home_search)
    elif not home_search:
        return find_cache(os.path.join(os.path.expanduser("~"), CACHE_FILE), True)
    return None

def update_cache(cache_path, data):
    with open(cache_path, "r") as f:
        cache = json.load(f)

    with open(cache_path, "w+") as f:
        cache.update(data)
        json.dump(cache, f)

def find_and_update_cache(basedir, scanned_dirs):
    cache_path = find_cache(basedir)
    if not cache_path:
        print_err("no %s found in parent path. Initialize cache in a directory with 'cdg - init'" % CACHE_FILE)
        return
    print_msg("updating cache %s" % cache_path)
    with open(cache_path, "r") as f:
        cache = parse_cache(f)
    for scanned_dir, alias in scanned_dirs:
        cache[scanned_dir] = alias
    with open(cache_path, "w") as f:
        for cached_dir, alias in cache.items():
            f.write("%s++%s\n"%(alias, cached_dir))

def scan_dir(basedirs):
    scanned_dirs = []

    def subdirs(sdir):
        subd = []
        try:
            for f in os.listdir(sdir):
                try:
                    if os.path.isdir(os.path.join(sdir,f)):
                        subd.append(os.path.join(sdir,f))
                except: # ignore access right problems
                    None
        except: # detto
            None
        return subd

    def scanner(root):
        for subdir in subdirs(root):
            if (not os.path.basename(subdir).startswith('.') or IGNORE_HIDDEN_FILES != 'yes') and not os.path.islink(subdir):
                scanned_dirs.append([subdir, '*'])
                scanner(os.path.realpath(subdir))

    for basedir in basedirs:
        scanned_dirs.append([basedir, '*'])
        scanner(os.path.realpath(basedir))

    print_msg("scanned %s, found %d dirs" % (basedirs, len(scanned_dirs)))
    find_and_update_cache(os.path.realpath('.'), scanned_dirs)

def parse_cache(fp):
    return dict([(x[1].strip(),x[0]) for x in (line.split('++') for line in fp.readlines())])

def read_cache(basedir='.'):
    cache_path = find_cache(basedir)
    if cache_path:
        with open(cache_path, "r") as f:
            return parse_cache(f)
    return {}

def init_cache():
    cache_path = os.path.join(os.path.realpath("."), CACHE_FILE)
    if os.path.exists(cache_path) and os.path.isdir(cache_path):
       print_err("path: %s is a dir, file expected" % cache_path)
       return
    if not os.path.exists(cache_path):
        with open(cache_path, "w") as f:
            None

def discover_caches(basedirs):
    cache_files = []
    for basedir in basedirs:
        cache_file = find_cache(basedir)
        if cache_file:
            cache_files.append(cache_file)
    print_msg("scanned %s, found dir_caches: %s" % (basedirs, cache_files))

def match_prefix(alias, cached_dir, prefix):
    if prefix[-1] == ':': # inline search 
        return alias == '*' and cached_dir.find(prefix[:-1])>-1 or alias != '*' and alias.find(prefix[:-1])>-1
    else: # only from the begining
        return alias == '*' and cached_dir.find(os.path.sep+prefix)>-1 or alias != '*' and alias.startswith(prefix)

def get_match_postfix(cached_dir, prefix):
    return re.sub('.*?'+os.path.sep + ('[^'+os.path.sep+']*' + prefix[:-1] if prefix[-1] == ':' else prefix) +'.*?'+os.path.sep+'?', os.path.sep, cached_dir, count=1)

def propose_dirs(prefixes):
    cache = read_cache()
    proposals = []
    for (cached_dir, alias) in cache.items():
        dir2match = cached_dir
        for prefix in prefixes:
            if prefix == '?':
                break
            if match_prefix(alias, dir2match, prefix):
                dir2match = get_match_postfix(dir2match, prefix)
                #print(cached_dir,dir2match)
            else:
                dir2match = None 
                break
        if dir2match:
            proposals.append(cached_dir)
            if alias != '*':
                proposals.append(alias)
    
    proposals.sort()
    proposals.sort(key=len)
    if prefixes[-1] != '?':
        print(" ".join(proposals[0:1]))
    else:
        print(" ".join(proposals))

def complete_basename(prefixes):
    cache = read_cache()
    for prefix in prefixes:
        for (cached_dir, alias) in cache.items():
            del cache[cached_dir]
            if match_prefix(alias, cached_dir, prefix): #consider only subdirs
                cache[re.sub('.*'+os.path.sep + ('[^'+os.path.sep+']*' if prefix[-1] == ':' else '') +prefix+'.*?'+os.path.sep, os.path.sep, cached_dir)] = alias
    dirs = cache.keys()

    if len(dirs) > 0 and len(prefixes)>0:
        prefix = prefixes[-1]
        basenames = list(set([basename for dirname in dirs for basename in dirname.split(os.path.sep) if basename.find(prefix)>-1]))
        print " ".join(basenames)

def process_controll(argv):
    if len(argv) == 0:
        print_help()
    else:
        if argv[0] == 'scan':
            scan_dir(argv[1:] or [os.path.realpath('.')])
        elif argv[0] == 'init':
            init_cache()
        elif argv[0] == 'discover':
            discover_caches(argv[1:] or [os.path.realpath('.')])
        elif argv[0] == 'complete':
            complete_basename(argv[1:])
        elif argv[0] == 'propose':
            propose_dirs(argv[1:])
        elif argv[0] == 'alias':
            print_msg("missing implementation")
        else:
            print_help()

#print "dirjumper %s" % sys.argv

IGNORE_HIDDEN_FILES = os.environ.get('DIRJUMPER_IGNORE_HIDDEN_FILES') or 'yes'

process_controll(sys.argv[1:])

